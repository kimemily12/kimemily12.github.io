<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<title>Emily Kim</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link href='https://fonts.googleapis.com/css?family=Open+Sans:300,600' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
	<table border="0" cellpadding="15" cellspacing="0" width="1000">

		<div class="container">
			<div>
				<table cellspacing="0">
					<tr>
						<td width="75%">
							<h1>Emily Kim</h1>
							<p>
								I am a PhD student at Carnegie Mellon University (CMU) <a
									href="https://www.ri.cmu.edu/">Robotics Institute (RI)</a>, advised by
								Professor <a href="https://www.ri.cmu.edu/ri-faculty/jessica-k-hodgins/">Jessica
									Hodgins</a>. My research focus
								spans broadly in the field of Computer Vision and Graphics, particularly in generating
								human datasets for various tasks and vehicle detection.
								I obtained my Bachelor of Science in Joint Computer Science-Math at Harvey Mudd College.
							</p>
							<p>
								My current research focuses on human dataset for generating universal Codec Avatars and
								evaluating the avatars generated from
								cross identity subjects (with one subject driving the appearance and the other subject
								driving the expression) using the autoencoder.
								In my previous research, I have focused on RGB video-based human motion tracking for
								human action recognition (HAR) for everyday gestures and error
								diagnosis of the exercise repetitions performed during physical therapy.
								My research field also spans to the practical adversarial attaacks on vehicle detection
								from satellite images. We use both the texture (2D) and
								the mesh-based (3D) attack that attacks both the computer vision-based detection
								algorithms as well as the human perceptive system.
							</p>
							<p>
								<a href="mailto:kimemily12@gmail.com">Email</a> [kimemily12 at gmail dot com]
								<b>&#183;</b> <a href="./CV.pdf">CV</a> [updated Mar 2024]
						</td>
						<td width="5%">
						</td>
						<td width="20%">
							<img style="max-height: 300px; max-width: 300px;" src="./portrait.jpg" border="0">
						</td>
					</tr>
				</table>
			</div>
		</div>

		<div class="container">
			<h2>News</h2>
			<ul style="list-style-type:dot">
				<ul>
					<li> (Mar 2024) The <a href="https://codec-avatars.github.io/cvpr24/">website</a> for CVPR Workshop
						on Codec Avatars is up!</li>
					<li> (Jan 2024) I am working with Julieta Martinez at Meta Reality Lab on the dataset and code
						release for Universal Codec Avatars. <br>
						This dataset will be presented at CVPR 2024 Codec Avatars Workshop.</li>
					<li> (Jan 2024) We presented our paper on activity recognition during the poster session at WACV
						2024.</li>
					<li> (Jan 2024) Our paper on activity recognition is released! Checkout our REMAG dataset suite <a
							href="http://humansensinglab.github.io/REMAG/">here</a>.</li>
					<li> (Oct 2023) Our paper on activity recognition has been accepted to WACV 2024! Check out our <a
							href="https://www.youtube.com/watch?v=hDlpJMyibBQ">video</a> and <a
							href="https://openaccess.thecvf.com/content/WACV2024/papers/Panev_Exploring_the_Impact_of_Rendering_Method_and_Motion_Quality_on_WACV_2024_paper.pdf">paper</a>.
					</li>
				</ul>
		</div>

		<div class="container">
			<div>
				<div>
					<h2>Publications</h2>
					<table cellspacing="15">
						<tr>
							<td width="20%">
								<img style="max-height: 250px; max-width: 250px;" src="Teaser.png" border="0">
							</td>

							<td>
								<p><b> Exploring the Impact of Rendering Method and Motion Quality <br>
										on Model Performance when Using a Multi-view Synthetic Data for Action
										Recognition </b>
									<br>
									Stanislav Panev*, <b>Emily Kim*</b>, Sai Abhishek Si Namburu, Desislava Nikolova,
									<br>
									Celso de Melo, Fernando De la Torre, Jessica Hodgins
									<br>
									<i>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)</i>
									<br>
									<a
										href="https://openaccess.thecvf.com/content/WACV2024/papers/Panev_Exploring_the_Impact_of_Rendering_Method_and_Motion_Quality_on_WACV_2024_paper.pdf">[Open
										Access]</a>
							</td>
						</tr>


						<tr>
							<td width="30%">
								<img style="max-height: 250px; max-width: 250px;" src="popchak_teaser.png" border="0">
							</td>
							<td>
								<p><b>Sensor-Based Evaluation of Physical Therapy Exercises</b>
									<br>
									Andrew Whitford, <b>Emily Kim</b>, Eni Halilaj, Keelan Enseki, Adam Popchak, Jessica
									Hodgins
									<br>
									<i>International Conference of the IEEE Engineering in Medicine and Biology Society
										(EMBC 2021)</i>
									<br>
									<a href="https://pubmed.ncbi.nlm.nih.gov/34892839/">[paper]</a>
							</td>
						</tr>

					</table>
				</div>
			</div>
		</div>

		<div class="container">
			<div>
				<div>
					<h2>Other Projects</h2>
					<table cellspacing="15">
						<tr>
							<!-- <td width="30%">
							<img style="max-height: 300px; max-width: 300px;" src="" border="0">
							</td> -->

							<td>
								<p><b> Learning to Attack Vehicle Detection Models Trained on Satellite Images using
										Both the 2D Texture and 3D Mesh Deformation in the Synthetic Domain </b>
									<br>
									We use a differentiable renderer to generate images and adversarially attack the
									vehicle detection models from satellite images in the synthetic domain.
									We use both texture (2D) and mesh-based (3D) to make it easy to implement the
									resulting vehicles in the real world scenario. Our goal is to attack both the
									computer vision-based models such as RetinaNet, FasterRCNN, and YOLO as well as the
									human perceptive system in a practical manner, thereby constraining
									the attack, i.e. limiting the colors of the adversarial texture to those extracted
									from the real-world background images, pixelating the texture, and
									limiting the amount of displacement of the mesh vertices during the mesh attack.
							</td>
						</tr>

					</table>
				</div>
			</div>
		</div>

		<div class="container">
			<h2>Experiences</h2>
			<!-- <ul style="list-style-type:dot"> -->
			<ul>
				<li>
					2022.5 - 2022.9: Lumiere Education Research Mentor
				</li>
				<li>
					2019.9 - Now: Carnegie Mellon University Robotics Institute PhD
				</li>
				<li>
					2018.5 - 2018.8: Juniper Networks, Inc. - Project Management Intern
				</li>
				<li>
					2015.8 - 2019.5: Harvey Mudd College, BS in Computer Science-Math
				</li>
			</ul>
		</div>
	</table>

	<embed type="text/html" src="googlee7b8b4b90cf937c4.html" width="10" height="20">

</body>

</html>